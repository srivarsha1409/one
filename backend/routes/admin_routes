# routes/admin_routes.py
import os
from fastapi import APIRouter, UploadFile, File, HTTPException
from fastapi import Depends
from fastapi.responses import JSONResponse
from sqlalchemy.orm import Session
from ..database import SessionLocal
from ..models import ResumeAnalysis
from ..utils.file_reader import extract_resume_text
from ..ai_resume_parser import call_openrouter
import json
from pathlib import Path
from datetime import datetime

router = APIRouter()

UPLOAD_DIR = Path(__file__).resolve().parents[1] / "uploads"
UPLOAD_DIR.mkdir(exist_ok=True)

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

@router.post("/upload_resume")
async def upload_resume(file: UploadFile = File(...), db: Session = Depends(get_db)):
    if not file.filename.lower().endswith((".pdf", ".docx", ".txt")):
        raise HTTPException(status_code=400, detail="Unsupported file type. Use pdf/docx/txt")

    content = await file.read()
    # save file
    save_path = UPLOAD_DIR / f"{int(datetime.utcnow().timestamp())}_{file.filename}"
    with open(save_path, "wb") as f:
        f.write(content)

    # extract text
    try:
        text = extract_resume_text(file.filename, content)
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Extraction error: {e}")

    # call AI parser
    try:
        parsed = call_openrouter(text)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"AI parsing error: {e}")

    # normalize and save
    skills = parsed.get("skills", {})
    tech = skills.get("technical", [])
    soft = skills.get("soft", [])
    area = skills.get("area_of_interest", [])

    record = ResumeAnalysis(
        filename=str(save_path.name),
        name=parsed.get("name"),
        email=parsed.get("email"),
        phone=parsed.get("phone"),
        linkedin=parsed.get("linkedin"),
        github=parsed.get("github"),
        leetcode=parsed.get("leetcode"),
        codechef=parsed.get("codechef"),
        codeforces=parsed.get("codeforces"),
        hackerrank=parsed.get("hackerrank"),
        skills_tech=json.dumps(tech),
        skills_soft=json.dumps(soft),
        skills_area_of_interest=json.dumps(area),
        ats_score=int(parsed.get("ats_score") or 0),
        role_match=int(parsed.get("role_match") or 0),
        word_count=int(parsed.get("word_count") or 0),
        summary=parsed.get("summary")
    )
    db.add(record)
    db.commit()
    db.refresh(record)

    return JSONResponse({"status": "success", "id": record.id, "data": parsed})

@router.get("/history")
def get_history(db: Session = Depends(get_db)):
    rows = db.query(ResumeAnalysis).order_by(ResumeAnalysis.created_at.desc()).limit(100).all()
    out = []
    for r in rows:
        out.append({
            "id": r.id,
            "filename": r.filename,
            "name": r.name,
            "email": r.email,
            "phone": r.phone,
            "linkedin": r.linkedin,
            "github": r.github,
            "skills_tech": json.loads(r.skills_tech) if r.skills_tech else [],
            "skills_soft": json.loads(r.skills_soft) if r.skills_soft else [],
            "skills_area_of_interest": json.loads(r.skills_area_of_interest) if r.skills_area_of_interest else [],
            "ats_score": r.ats_score,
            "role_match": r.role_match,
            "word_count": r.word_count,
            "summary": r.summary,
            "created_at": r.created_at.isoformat()
        })
    return {"history": out}
